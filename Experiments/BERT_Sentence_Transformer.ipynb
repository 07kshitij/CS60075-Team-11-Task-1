{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Sentence Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nyXxksyCnBn"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6kBZKrPC1NA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import csv\n",
        "from scipy import stats\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ5m63qADN8F"
      },
      "source": [
        "device = 'cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_x-wp-IC2F6"
      },
      "source": [
        "SINGLE_TRAIN_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/train/lcp_single_train.tsv\"\n",
        "SINGLE_TEST_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/test-labels/lcp_single_test.tsv\"\n",
        "MULTI_TRAIN_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/train/lcp_multi_train.tsv\"\n",
        "MULTI_TEST_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/test-labels/lcp_multi_test.tsv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMlq_5KVDnmK"
      },
      "source": [
        "model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slTZPFW3DUHl"
      },
      "source": [
        "def prepare_dataset(TRAIN_DATAPATH, TEST_DATAPATH):\n",
        "    df_train = pd.read_csv(TRAIN_DATAPATH, sep = '\\t', quotechar=\"'\", quoting = csv.QUOTE_NONE)\n",
        "    df_test = pd.read_csv(TEST_DATAPATH, sep = '\\t', quotechar=\"'\", quoting = csv.QUOTE_NONE)\n",
        "    df_train['complexity'] = df_train['complexity'].astype(float)\n",
        "    df_test['complexity'] = df_test['complexity'].astype(float)\n",
        "    train_input = [i for i in df_train['sentence']]\n",
        "    test_input = [i for i in df_test['sentence']]\n",
        "    labels = [i for i in df_train['complexity']]\n",
        "    test_labels = [i for i in df_test['complexity']]\n",
        "    train_emb = model.encode(train_input)\n",
        "    test_emb = model.encode(test_input)\n",
        "    return train_emb, test_emb, labels, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3F6cWWjDZ6I"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, 1536)\n",
        "    self.linear2 = nn.Linear(1536, 3072)\n",
        "    self.linear3 = nn.Linear(3072, 3072)\n",
        "    self.linear4 = nn.Linear(3072, 1536)\n",
        "    self.linear5 = nn.Linear(1536, 768)\n",
        "    self.linear6 = nn.Linear(768, 768)\n",
        "    self.linear7 = nn.Linear(768, 768)\n",
        "    self.linear8 = nn.Linear(768, 256)\n",
        "    self.linear9 = nn.Linear(256, 128)\n",
        "    self.linear10 = nn.Linear(128, 64)\n",
        "    self.linear11 = nn.Linear(64, 1)\n",
        "\n",
        "  def forward(self, input):                                      # gelu or elu in initial layers is quite good, gives 0.5 r\n",
        "    out = F.gelu(self.linear1(input))\n",
        "    out = F.gelu(self.linear2(out))\n",
        "    out = F.gelu(self.linear3(out))\n",
        "    out = F.gelu(self.linear4(out))\n",
        "    out = F.gelu(self.linear5(out))\n",
        "    out = F.gelu(self.linear6(out))\n",
        "    out = F.gelu(self.linear7(out))\n",
        "    out = F.gelu(self.linear8(out))\n",
        "    out = F.gelu(self.linear9(out))\n",
        "    out = F.gelu(self.linear10(out))\n",
        "    out = F.sigmoid(self.linear11(out))\n",
        "    out = torch.squeeze(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmz-dP6VRqv8"
      },
      "source": [
        "def pearson_loss(target, output):\n",
        "    eps = 0.000001\n",
        "    output_mean = torch.mean(output)\n",
        "    target_mean = torch.mean(target)\n",
        "    x = output - output_mean.expand_as(output)\n",
        "    y = target - target_mean.expand_as(target)\n",
        "    pearson = torch.dot(x, y)/ ((torch.std(output) + eps) * (torch.std(target) + eps))\n",
        "    loss = (-1.0 * pearson / len(target))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wASn_gMELDV"
      },
      "source": [
        "input_dim = 768\n",
        "print(\"++++Input Dimension of NN: \" + str(input_dim))\n",
        "nn_num_epochs = 1500\n",
        "nn_model = NN(input_dim)\n",
        "nn_model.to(device)\n",
        "nn_optimizer = optim.Adam(nn_model.parameters(), lr = 0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHJM2kxZENRT"
      },
      "source": [
        "def train_nn(nn_model, input):\n",
        "    nn_model.train()\n",
        "    nn_optimizer.zero_grad()\n",
        "    output = nn_model(input)                       \n",
        "    loss = pearson_loss(labels, output)\n",
        "    loss.backward()\n",
        "    nn_optimizer.step()\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWzVEio6EPJq"
      },
      "source": [
        "def test_nn(nn_model, input):\n",
        "    nn_model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = nn_model(input)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpC_BL9fETVx"
      },
      "source": [
        "def calculate_metrics(y, y_hat):\n",
        "    vx = y.astype(float)\n",
        "    vy = y_hat.astype(float)\n",
        "    pearsonR = np.corrcoef(vx, vy)[0, 1]\n",
        "    spearmanRho = stats.spearmanr(vx, vy)\n",
        "    MSE = np.mean((vx - vy) ** 2)\n",
        "    MAE = np.mean(np.absolute(vx - vy))\n",
        "    RSquared = (pearsonR ** 2)\n",
        "\n",
        "    print(\"Pearson's R: {}\".format(pearsonR))\n",
        "    print(\"Spearman's rho: {}\".format(spearmanRho))\n",
        "    print(\"R Squared: {}\".format(RSquared))\n",
        "    print(\"MSE: {}\".format(MSE))\n",
        "    print(\"MAE: {}\".format(MAE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so4RTlkoScVy"
      },
      "source": [
        "train_emb, test_emb, labels, test_labels = prepare_dataset(SINGLE_TRAIN_DATAPATH, SINGLE_TEST_DATAPATH)\n",
        "nn_input = torch.tensor(train_emb, device = device, requires_grad = True)\n",
        "labels = torch.tensor(labels, dtype = torch.float32, device = device, requires_grad = True)\n",
        "nn_input_test = torch.tensor(test_emb, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSXFjOtBESNJ"
      },
      "source": [
        "print(\"++++++Running for single++\")\n",
        "for epoch in range(nn_num_epochs):\n",
        "    nn_train_loss = train_nn(nn_model, nn_input)\n",
        "    print(\"Epoch {} : {}\".format(epoch + 1, nn_train_loss))\n",
        "    output = test_nn(nn_model, nn_input_test)\n",
        "    print(\"------Metrics for test-----\")\n",
        "    calculate_metrics(np.array(test_labels), np.array(output.tolist()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYiefymvSyvG"
      },
      "source": [
        "train_emb, test_emb, labels, test_labels = prepare_dataset(MULTI_TRAIN_DATAPATH, MULTI_TEST_DATAPATH)\n",
        "nn_input = torch.tensor(train_emb, device = device, requires_grad = True)\n",
        "labels = torch.tensor(labels, dtype = torch.float32, device = device, requires_grad = True)\n",
        "nn_input_test = torch.tensor(test_emb, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oOH6n7ES7sG"
      },
      "source": [
        "print(\"++++++Running for multi+++\")\n",
        "for epoch in range(nn_num_epochs):\n",
        "    nn_train_loss = train_nn(nn_model, nn_input)\n",
        "    print(\"Epoch {} : {}\".format(epoch + 1, nn_train_loss))\n",
        "    output = test_nn(nn_model, nn_input_test)\n",
        "    print(\"------Metrics for test-----\")\n",
        "    calculate_metrics(np.array(test_labels), np.array(output.tolist()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}