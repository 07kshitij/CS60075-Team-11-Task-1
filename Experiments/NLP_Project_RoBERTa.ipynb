{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP Project RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HWCeIuUMHNx"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtNeO3LJbI3T"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import csv\n",
        "from scipy import stats\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee61961GjXPH"
      },
      "source": [
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtZUQ9bgc6hf"
      },
      "source": [
        "SINGLE_TRAIN_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/train/lcp_single_train.tsv\"\n",
        "SINGLE_TEST_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/test-labels/lcp_single_test.tsv\"\n",
        "MULTI_TRAIN_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/train/lcp_multi_train.tsv\"\n",
        "MULTI_TEST_DATAPATH = \"https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/test-labels/lcp_multi_test.tsv\"\n",
        "single_train_filepath = \"/content/sample_data/single_train.csv\"\n",
        "single_test_filepath = \"/content/sample_data/single_test.csv\"\n",
        "multi_train_filepath = \"/content/sample_data/multi_train.csv\"\n",
        "multi_test_filepath = \"/content/sample_data/multi_test.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKMZicAII8iu"
      },
      "source": [
        "k = 1            # token append number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAJc4x0Nebxm"
      },
      "source": [
        "def prepare_dataset(TRAIN_DATAPATH, TEST_DATAPATH, train_filepath, test_filepath):\n",
        "    df_train = pd.read_csv(TRAIN_DATAPATH, sep = '\\t', quotechar=\"'\", quoting = csv.QUOTE_NONE)\n",
        "    df_test = pd.read_csv(TEST_DATAPATH, sep = '\\t', quotechar=\"'\", quoting = csv.QUOTE_NONE)\n",
        "    df_train['complexity'] = df_train['complexity'].astype(float)\n",
        "    df_test['complexity'] = df_test['complexity'].astype(float)\n",
        "    for i in range(len(df_train)):\n",
        "        first = str(df_train['token'][i]) + \" [SEP] \"\n",
        "        last = \" [SEP] \" + str(df_train['token'][i])\n",
        "        for _ in range(k):\n",
        "            df_train['sentence'][i] = first + df_train['sentence'][i] + last\n",
        "    for i in range(len(df_test)):\n",
        "        first = str(df_test['token'][i]) + \" [SEP] \"\n",
        "        last = \" [SEP] \" + str(df_test['token'][i])\n",
        "        for _ in range(k):\n",
        "            df_test['sentence'][i] = first + df_test['sentence'][i] + last\n",
        "    df_train = df_train.drop(['id', 'corpus', 'token'], axis = 1)\n",
        "    df_test = df_test.drop(['id', 'corpus', 'token'], axis = 1)\n",
        "    df_train = df_train[['complexity', 'sentence']]\n",
        "    df_test = df_test[['complexity', 'sentence']]\n",
        "    df_train.to_csv(train_filepath, index = False)\n",
        "    df_test.to_csv(test_filepath, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za0-FKknnt4E"
      },
      "source": [
        "device = 'cuda'\n",
        "batch_size = 4\n",
        "num_epochs = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Din8SFNMT16"
      },
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvgOSFuvbXx5"
      },
      "source": [
        "def prepare_iterators(train_filepath, test_filepath):\n",
        "    label = Field(sequential = False, use_vocab = False, batch_first = True, dtype = torch.float32)\n",
        "    text = Field(use_vocab = False, tokenize = tokenizer.encode, lower = False, batch_first = True, pad_token = PAD_INDEX, unk_token = UNK_INDEX)\n",
        "    fields = [('complexity', label), ('sentence', text)]\n",
        "    train = TabularDataset(path = train_filepath, format = 'csv', skip_header = True, fields = fields)\n",
        "    train_iter = BucketIterator(train, batch_size = batch_size, sort_key = lambda x: len(x.sentence), device = device, train = True, sort = True, sort_within_batch = True)\n",
        "    test_label = Field(sequential = False, use_vocab = False, batch_first = True, dtype = torch.float32)\n",
        "    test_text = Field(use_vocab = False, tokenize = tokenizer.encode, lower = False, batch_first = True, pad_token = PAD_INDEX, unk_token = UNK_INDEX)\n",
        "    test_fields = [('complexity', test_label), ('sentence', test_text)]\n",
        "    test = TabularDataset(path = test_filepath, format = 'csv', skip_header = True, fields = test_fields)\n",
        "    test_iter = BucketIterator(test, batch_size = batch_size, sort_key = lambda x: len(x.sentence), device = device, train = False, sort = True, sort_within_batch = True)\n",
        "    return train_iter, test_iter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLKZQSUeodOJ"
      },
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\")\n",
        "model.config.num_labels = 1\n",
        "model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWilrrIhvzWa"
      },
      "source": [
        "def train_model(model, iterator):\n",
        "    epoch_loss = 0.0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        text = batch.sentence\n",
        "        label = batch.complexity\n",
        "        optimizer.zero_grad()\n",
        "        output = model(text)                       \n",
        "        logits = output.logits[:, : 1]                    \n",
        "        logits = torch.sigmoid(torch.squeeze(logits))\n",
        "        try:\n",
        "            predicted.extend(logits.tolist())\n",
        "            labels.extend(label.tolist())\n",
        "            loss = criterion(label, logits)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        except TypeError:\n",
        "            pass\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t55EKZ0AUMTl"
      },
      "source": [
        "def test_model(model, iterator):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.sentence\n",
        "            label = batch.complexity\n",
        "            output = model(text)\n",
        "            logits = output.logits[:, : 1]                    \n",
        "            logits = torch.sigmoid(torch.squeeze(logits))\n",
        "            try:\n",
        "                test_predicted.extend(logits.tolist())\n",
        "                test_labels.extend(label.tolist())\n",
        "            except TypeError:\n",
        "                pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6mtsea4tpBj"
      },
      "source": [
        "def calculate_metrics(y, y_hat):\n",
        "    vx = y.astype(float)\n",
        "    vy = y_hat.astype(float)\n",
        "    pearsonR = np.corrcoef(vx, vy)[0, 1]\n",
        "    spearmanRho = stats.spearmanr(vx, vy)\n",
        "    MSE = np.mean((vx - vy) ** 2)\n",
        "    MAE = np.mean(np.absolute(vx - vy))\n",
        "    RSquared = (pearsonR ** 2)\n",
        "\n",
        "    print(\"Pearson's R: {}\".format(pearsonR))\n",
        "    print(\"Spearman's rho: {}\".format(spearmanRho))\n",
        "    print(\"R Squared: {}\".format(RSquared))\n",
        "    print(\"MSE: {}\".format(MSE))\n",
        "    print(\"MAE: {}\".format(MAE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i8MrZZtMlQ5"
      },
      "source": [
        "prepare_dataset(SINGLE_TRAIN_DATAPATH, SINGLE_TEST_DATAPATH, single_train_filepath, single_test_filepath)\n",
        "train_iter, test_iter = prepare_iterators(single_train_filepath, single_test_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpG1HHmIwDF1"
      },
      "source": [
        "print(\"++++++Running for single+++++\")\n",
        "for epoch in range(num_epochs):\n",
        "    labels = []\n",
        "    predicted = []\n",
        "    train_loss = train_model(model, train_iter)\n",
        "    print(f'\\t Epoch: {epoch + 1} | Train Loss: {train_loss: }')\n",
        "    print(\"------Metrics for train------\")\n",
        "    calculate_metrics(np.array(labels), np.array(predicted))\n",
        "    test_labels = []\n",
        "    test_predicted = []\n",
        "    test_model(model, test_iter)\n",
        "    print(\"------Metrics for test-------\")\n",
        "    calculate_metrics(np.array(test_labels), np.array(test_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRbbIEFOMzsw"
      },
      "source": [
        "prepare_dataset(MULTI_TRAIN_DATAPATH, MULTI_TEST_DATAPATH, multi_train_filepath, multi_test_filepath)\n",
        "train_iter, test_iter = prepare_iterators(multi_train_filepath, multi_test_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WtcRseNM6xH"
      },
      "source": [
        "print(\"++++++Running for multi++++++\")\n",
        "for epoch in range(num_epochs):\n",
        "    labels = []\n",
        "    predicted = []\n",
        "    train_loss = train_model(model, train_iter)\n",
        "    print(f'\\t Epoch: {epoch + 1} | Train Loss: {train_loss: }')\n",
        "    print(\"------Metrics for train------\")\n",
        "    calculate_metrics(np.array(labels), np.array(predicted))\n",
        "    test_labels = []\n",
        "    test_predicted = []\n",
        "    test_model(model, test_iter)\n",
        "    print(\"------Metrics for test-------\")\n",
        "    calculate_metrics(np.array(test_labels), np.array(test_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}